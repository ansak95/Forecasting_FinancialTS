{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akrim/Documents/Data Science/Stage Seoul\n"
     ]
    }
   ],
   "source": [
    "cd /Users/akrim/Documents/Data Science/Stage Seoul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/akrim/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:438: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=3)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 64)             18944     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 64)             33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 87,171\n",
      "Trainable params: 87,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import pandas_datareader.data as web\n",
    "from sklearn import preprocessing\n",
    "from pandas import datetime\n",
    "from keras.optimizers import Adam\n",
    "#import quandl\n",
    "from sklearn.externals import joblib\n",
    "#import backtest as twp #This is for the return and other things\n",
    "import random, timeit\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "\n",
    "def obv(df, n, col, vol):\n",
    "    \"\"\"Calculate On-Balance Volume for given data.\n",
    "    \n",
    "    :param df: pandas.DataFrame\n",
    "    :param n: \n",
    "    :return: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    OBV = [0]\n",
    "    while i < (df.shape[0]-1):\n",
    "        if df.loc[df.index[i + 1], col] - df.loc[df.index[i], col] > 0:\n",
    "            OBV.append(df.loc[df.index[i + 1], vol])\n",
    "        if df.loc[df.index[i + 1], col] - df.loc[df.index[i], col] == 0:\n",
    "            OBV.append(0)\n",
    "        if df.loc[df.index[i + 1], col] - df.loc[df.index[i], col] < 0:\n",
    "            OBV.append(-df.loc[df.index[i + 1], vol])\n",
    "        i = i + 1\n",
    "    OBV = pd.Series(OBV)\n",
    "    OBV_ma = pd.Series(OBV.rolling(n, min_periods=n).mean(), name='OBV_' + str(n))\n",
    "    return OBV_ma\n",
    "\n",
    "def RSI(df, n, high, low): \n",
    "    \"\"\"Calculate Relative Strength Index for given data.\n",
    "    \n",
    "    :param df: pandas.DataFrame\n",
    "    :param n: \n",
    "    :return: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    i = 0  \n",
    "    UpI = [0]  \n",
    "    DoI = [0]  \n",
    "    while i + 1 <= (data.shape[0]-1):  \n",
    "        UpMove = df[high][i+1] - df[high][i]  \n",
    "        DoMove = df[low][i] - df[low][i+1]\n",
    "        if UpMove > DoMove and UpMove > 0:  \n",
    "            UpD = UpMove  \n",
    "        else: UpD = 0  \n",
    "        UpI.append(UpD)  \n",
    "        if DoMove > UpMove and DoMove > 0:  \n",
    "            DoD = DoMove  \n",
    "        else: DoD = 0  \n",
    "        DoI.append(DoD)  \n",
    "        i = i + 1  \n",
    "    UpI = pd.Series(UpI)  \n",
    "    DoI = pd.Series(DoI)  \n",
    "    #print(UpI)\n",
    "    PosDI = pd.Series(UpI.ewm(span = n, min_periods = n - 1).mean())  \n",
    "    NegDI = pd.Series(DoI.ewm(span = n, min_periods = n - 1).mean())  \n",
    "    RSI = pd.Series(PosDI / (PosDI + NegDI), name = 'RSI_' + str(n))  \n",
    "    #df = df.join(RSI)  \n",
    "    return RSI\n",
    "\n",
    "#MACD, MACD Signal and MACD difference  \n",
    "def MACD(df, n_fast, n_slow, col):  \n",
    "    EMAfast = pd.Series(df[col].ewm(span = n_fast, min_periods = n_slow - 1,adjust=False).mean())  \n",
    "    EMAslow = pd.Series(df[col].ewm(span = n_slow, min_periods = n_slow - 1,adjust=False).mean())  \n",
    "    MACD = pd.Series(EMAfast - EMAslow, name = 'MACD_' + str(n_fast) + '_' + str(n_slow))  \n",
    "    MACDsign = pd.Series(MACD.ewm(span = 9, min_periods = 8,adjust=False).mean(), \n",
    "                         name = 'MACDsign_' + str(n_fast) + '_' + str(n_slow))  \n",
    "    MACDdiff = pd.Series(MACD - MACDsign, name = 'MACDdiff_' + str(n_fast) + '_' + str(n_slow))  \n",
    "    #df = df.join(MACD)  \n",
    "    #df = df.join(MACDsign)  \n",
    "    #df = df.join(MACDdiff)  \n",
    "    return MACD\n",
    "\n",
    "\n",
    "\n",
    "def tradeBracket(price,entryBar,upper=None, lower=None, timeout=None):\n",
    "    '''\n",
    "    trade a  bracket on price series, return price delta and exit bar #\n",
    "    Input\n",
    "    ------\n",
    "        price : numpy array of price values\n",
    "        entryBar: entry bar number, *determines entry price*\n",
    "        upper : high stop\n",
    "        lower : low stop\n",
    "        timeout : max number of periods to hold\n",
    "\n",
    "    Returns exit price  and number of bars held\n",
    "\n",
    "    '''\n",
    "    assert isinstance(price, np.ndarray) , 'price must be a numpy array'\n",
    "    \n",
    "    \n",
    "    # create list of exit indices and add max trade duration. Exits are relative to entry bar\n",
    "    if timeout: # set trade length to timeout or series length\n",
    "        exits = [min(timeout,len(price)-entryBar-1)]\n",
    "    else:\n",
    "        exits = [len(price)-entryBar-1] \n",
    "        \n",
    "    p = price[entryBar:entryBar+exits[0]+1] # subseries of price\n",
    "    \n",
    "    # extend exits list with conditional exits\n",
    "    # check upper bracket\n",
    "    if upper:\n",
    "        assert upper>p[0] , 'Upper bracket must be higher than entry price '\n",
    "        idx = np.where(p>upper)[0] # find where price is higher than the upper bracket\n",
    "        if idx.any(): \n",
    "            exits.append(idx[0]) # append first occurence\n",
    "    # same for lower bracket\n",
    "    if lower:\n",
    "        assert lower<p[0] , 'Lower bracket must be lower than entry price '\n",
    "        idx = np.where(p<lower)[0]\n",
    "        if idx.any(): \n",
    "            exits.append(idx[0]) \n",
    "   \n",
    "    \n",
    "    exitBar = min(exits) # choose first exit    \n",
    "  \n",
    "    \n",
    "\n",
    "    return p[exitBar], exitBar\n",
    "\n",
    "\n",
    "class Backtest(object):\n",
    "    \"\"\"\n",
    "    Backtest class, simple vectorized one. Works with pandas objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,price, signal, signalType='capital',initialCash = 1000, roundShares=True):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        \n",
    "        *price*  Series with instrument price.\n",
    "        *signal* Series with capital to invest (long+,short-) or number of shares. \n",
    "        *signalType* capital to bet or number of shares 'capital' mode is default.\n",
    "        *initialCash* starting cash. \n",
    "        *roundShares* round off number of shares to integers\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #TODO: add auto rebalancing\n",
    "        \n",
    "        # check for correct input\n",
    "        assert signalType in ['capital','shares'], \"Wrong signal type provided, must be 'capital' or 'shares'\"\n",
    "        \n",
    "        #save internal settings to a dict\n",
    "        self.settings = {'signalType':signalType}\n",
    "        \n",
    "        # first thing to do is to clean up the signal, removing nans and duplicate entries or exits\n",
    "        self.signal = signal.ffill().fillna(0)\n",
    "        \n",
    "        # now find dates with a trade\n",
    "        tradeIdx = self.signal.diff().fillna(0) !=0 # days with trades are set to True\n",
    "        if signalType == 'shares':\n",
    "            self.trades = self.signal[tradeIdx] # selected rows where tradeDir changes value. trades are in Shares\n",
    "        elif signalType =='capital':\n",
    "            self.trades = (self.signal[tradeIdx]/price[tradeIdx])\n",
    "            if roundShares:\n",
    "                self.trades = self.trades.round()\n",
    "        \n",
    "        # now create internal data structure \n",
    "        self.data = pd.DataFrame(index=price.index , columns = ['price','shares','value','cash','pnl'])\n",
    "        self.data['price'] = price\n",
    "        \n",
    "        self.data['shares'] = self.trades.reindex(self.data.index).ffill().fillna(0)\n",
    "        self.data['value'] = self.data['shares'] * self.data['price']\n",
    "       \n",
    "        delta = self.data['shares'].diff() # shares bought sold\n",
    "        \n",
    "        self.data['cash'] = (-delta*self.data['price']).fillna(0).cumsum()+initialCash\n",
    "        self.data['pnl'] = self.data['cash']+self.data['value']-initialCash\n",
    "      \n",
    "      \n",
    "    @property\n",
    "    def sharpe(self):\n",
    "        ''' return annualized sharpe ratio of the pnl '''\n",
    "        pnl = (self.data['pnl'].diff()).shift(-1)[self.data['shares']!=0] # use only days with position.\n",
    "        return sharpe(pnl)  # need the diff here as sharpe works on daily returns.\n",
    "        \n",
    "    @property\n",
    "    def pnl(self):\n",
    "        '''easy access to pnl data column '''\n",
    "        return self.data['pnl']\n",
    "    \n",
    "    def plotTrades(self):\n",
    "        \"\"\" \n",
    "        visualise trades on the price chart \n",
    "            long entry : green triangle up\n",
    "            short entry : red triangle down\n",
    "            exit : black circle\n",
    "        \"\"\"\n",
    "        l = ['price']\n",
    "        \n",
    "        p = self.data['price']\n",
    "        p.plot(style='x-')\n",
    "\n",
    "        idx = (self.data['shares'] > 0) | (self.data['shares'] > 0).shift(1) \n",
    "        if idx.any():\n",
    "            p[idx].plot(style='go')\n",
    "            l.append('long')\n",
    "        \n",
    "        #colored line for short positions    \n",
    "        idx = (self.data['shares'] < 0) | (self.data['shares'] < 0).shift(1) \n",
    "        if idx.any():\n",
    "            p[idx].plot(style='ro')\n",
    "            l.append('short')\n",
    "\n",
    "        plt.xlim([p.index[0],p.index[-1]]) # show full axis\n",
    "        \n",
    "        plt.legend(l,loc='best')\n",
    "        plt.title('trades')\n",
    "        \n",
    "        \n",
    "class ProgressBar:\n",
    "    def __init__(self, iterations):\n",
    "        self.iterations = iterations\n",
    "        self.prog_bar = '[]'\n",
    "        self.fill_char = '*'\n",
    "        self.width = 50\n",
    "        self.__update_amount(0)\n",
    "\n",
    "    def animate(self, iteration):\n",
    "        sys.stdout.flush()\n",
    "        self.update_iteration(iteration + 1)\n",
    "\n",
    "    def update_iteration(self, elapsed_iter):\n",
    "        self.__update_amount((elapsed_iter / float(self.iterations)) * 100.0)\n",
    "        self.prog_bar += '  %d of %s complete' % (elapsed_iter, self.iterations)\n",
    "\n",
    "    def __update_amount(self, new_amount):\n",
    "        percent_done = int(round((new_amount / 100.0) * 100.0))\n",
    "        all_full = self.width - 2\n",
    "        num_hashes = int(round((percent_done / 100.0) * all_full))\n",
    "        self.prog_bar = '[' + self.fill_char * num_hashes + ' ' * (all_full - num_hashes) + ']'\n",
    "        pct_place = (len(self.prog_bar) // 2) - len(str(percent_done))\n",
    "        pct_string = '%d%%' % percent_done\n",
    "        self.prog_bar = self.prog_bar[0:pct_place] + \\\n",
    "            (pct_string + self.prog_bar[pct_place + len(pct_string):])\n",
    "    def __str__(self):\n",
    "        return str(self.prog_bar)\n",
    "    \n",
    "def sharpe(pnl):\n",
    "    return  np.sqrt(250)*pnl.mean()/pnl.std()\n",
    "\n",
    "\n",
    "#download data from yahoo! finance\n",
    "\"\"\"\n",
    "data source: http://finance.yahoo.com/\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class YahooDailyReader():\n",
    "    \n",
    "    def __init__(self, symbol=None, start=None, end=None):\n",
    "        import datetime, time\n",
    "        self.symbol = symbol\n",
    "        \n",
    "        # initialize start/end dates if not provided\n",
    "        if end is None:\n",
    "            end = datetime.datetime.today()\n",
    "        if start is None:\n",
    "            start = datetime.datetime(1980,2,1)\n",
    "        \n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        \n",
    "        # convert dates to unix time strings\n",
    "        unix_start = int(time.mktime(self.start.timetuple()))\n",
    "        day_end = self.end.replace(hour=23, minute=59, second=59)\n",
    "        unix_end = int(time.mktime(day_end.timetuple()))\n",
    "        \n",
    "        url = 'https://finance.yahoo.com/quote/{}/history?'\n",
    "        url += 'period1={}&period2={}'\n",
    "        url += '&filter=history'\n",
    "        url += '&interval=1d'\n",
    "        url += '&frequency=1d'\n",
    "        self.url = url.format(self.symbol, unix_start, unix_end)\n",
    "        \n",
    "    def read(self):\n",
    "        import requests, re, json\n",
    "       \n",
    "        r = requests.get(self.url)\n",
    "        \n",
    "        ptrn = r'root\\.App\\.main = (.*?);\\n}\\(this\\)\\);'\n",
    "        txt = re.search(ptrn, r.text, re.DOTALL).group(1)\n",
    "        jsn = json.loads(txt)\n",
    "        df = pd.DataFrame(\n",
    "                jsn['context']['dispatcher']['stores']\n",
    "                ['HistoricalPriceStore']['prices']\n",
    "                )\n",
    "        df.insert(0, 'symbol', self.symbol)\n",
    "        df['Date'] = pd.to_datetime(df['date'], unit='s').dt.date\n",
    "        \n",
    "        # drop rows that aren't prices\n",
    "        df = df.dropna(subset=['close'])\n",
    "        \n",
    "        df = df[['Date', 'high', 'low', 'open', 'close', \n",
    "                 'volume', 'adjclose']]\n",
    "        df = df.set_index('Date')\n",
    "        df.index=pd.to_datetime(df.index)\n",
    "        return df\n",
    "    \n",
    "\n",
    "\n",
    "#Initialize first state, all items are placed deterministically\n",
    "def init_state(indata, test=False):\n",
    "    close = indata['close'].values\n",
    "    diff = np.diff(close) #Take the diff of the close values\n",
    "    diff = np.insert(diff, 0, 0) #Insert 0 in the first position in order to \n",
    "    sma20 = indata.rolling(window=14) #Take the simple mean average for 15 days\n",
    "    sma100 = indata.rolling(window=50)\n",
    "    ema_short = indata.close.ewm(span=14, adjust=False).mean()\n",
    "    ema_long = indata.close.ewm(span=50, adjust=False).mean()\n",
    "    obv14 = obv(indata, 14, 'close', 'volume')\n",
    "    rsi14 = RSI(data, 14, 'high', 'low')\n",
    "    macd9 = MACD(data, 12, 26, 'close')\n",
    "\n",
    "    #--- Preprocess data\n",
    "    xdata = np.column_stack((close, diff, sma20.mean().close, close-sma20.mean().close, \n",
    "                             sma20.mean().close-sma100.mean().close, ema_short, close-ema_short, \n",
    "                             ema_short-ema_long,obv14.values, )) \n",
    "    xdata = np.nan_to_num(xdata) #Delete the NaN values\n",
    "   \n",
    "    if test == False:\n",
    "        scaler = preprocessing.StandardScaler() #Standard scaler (unit variance and remove mean)\n",
    "        xdata = np.expand_dims(scaler.fit_transform(xdata), axis=1) \n",
    "        joblib.dump(scaler, 'data/scaler.pkl')\n",
    "   \n",
    "    elif test == True:\n",
    "        scaler = joblib.load('data/scaler.pkl')\n",
    "        xdata = np.expand_dims(scaler.fit_transform(xdata), axis=1)\n",
    "    state = xdata[0:1, 0:1, :] #Take only the  first values of the first day (i.e the first state)\n",
    "    \n",
    "    return state, xdata, close\n",
    "                            \n",
    "                            \n",
    "\n",
    "#Take Action\n",
    "def take_action(state, xdata, action, signal, time_step):\n",
    "    #this should generate a list of trade signals that at evaluation time are fed to the backtester\n",
    "    #the backtester should get a list of trade signals and a list of price data for the assett\n",
    "    \n",
    "    #make necessary adjustments to state and then return it\n",
    "    time_step += 1\n",
    "    \n",
    "    #if the current iteration is the last state (\"terminal state\") then set terminal_state to 1\n",
    "    if time_step + 1 == xdata.shape[0]:\n",
    "        state = xdata[time_step-1:time_step, 0:1, :] #avant dernier day\n",
    "        terminal_state = 1 #on arrive au dernier jour\n",
    "        signal.loc[time_step] = 0 #signal loc 2012 avant dernier\n",
    "\n",
    "        return state, time_step, signal, terminal_state\n",
    "\n",
    "    #move the market data window one step forward\n",
    "    state = xdata[time_step-1:time_step, 0:1, :] #next state\n",
    "    #take action\n",
    "    if action == 1:\n",
    "        signal.loc[time_step] = 50 #Sell\n",
    "    elif action == 2:\n",
    "        signal.loc[time_step] = -50 #Buy\n",
    "    else:\n",
    "        signal.loc[time_step] = 0 #Hold\n",
    "    #print(state)\n",
    "    terminal_state = 0\n",
    "    #print(signal)\n",
    "\n",
    "    return state, time_step, signal, terminal_state\n",
    "\n",
    "\n",
    "#Get Reward, the reward is returned at the end of an episode\n",
    "def get_reward(new_state, time_step, action, xdata, signal, terminal_state, eval=False, epoch=0):\n",
    "    reward = 0\n",
    "    signal.fillna(value=0, inplace=True)\n",
    "\n",
    "    if eval == False:\n",
    "        bt =Backtest(pd.Series(data=[x for x in xdata[time_step-2:time_step]], index=signal[time_step-2:time_step].index.values), signal[time_step-2:time_step], signalType='shares')\n",
    "        price_t = bt.data['price'].iloc[-1] #Get the last price p(t)\n",
    "        price_t_1 = bt.data['price'].iloc[-2] #price p(t-1)\n",
    "        #reward =(bt.data['shares'].iloc[-1]) * ((price_t) - price_t_1) / price_t_1 )\n",
    "        shares_t = (bt.data['shares'].iloc[-1])\n",
    "        reward =(price_t - price_t_1)*shares_t\n",
    "\n",
    "    if terminal_state == 1 and eval == True:\n",
    "        #save a figure of the test set\n",
    "        bt = Backtest(pd.Series(data=[x for x in xdata], index=signal.index.values), signal, signalType='shares')\n",
    "        reward = bt.pnl.iloc[-1]\n",
    "        plt.figure(figsize=(3,4))\n",
    "        bt.plotTrades()\n",
    "        plt.axvline(x=400, color='black', linestyle='--')\n",
    "        plt.text(250, 400, 'training data')\n",
    "        plt.text(450, 400, 'test data')\n",
    "        plt.suptitle(str(epoch))\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MAIN \n",
    "\n",
    "data = YahooDailyReader('%5EGSPC').read() \n",
    "data = data.iloc[::-1]\n",
    "\n",
    "\n",
    "START_TRAIN_DATE = '2010-01-01'\n",
    "END_TRAIN_DATE = '2017-12-31'\n",
    "START_TEST_DATE = '2018-01-01'\n",
    "#END_TEST_DATE = '2018-03-09'\n",
    "\n",
    "X_train = data.loc[(data.index <= pd.to_datetime(END_TRAIN_DATE)) & (data.index >= pd.to_datetime(START_TRAIN_DATE))]  #2013 rows\n",
    "X_test = data.loc[(data.index >= pd.to_datetime(START_TEST_DATE))] #& (data.index <= pd.to_datetime(END_TEST_DATE))] #47 rows\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "tsteps = 7\n",
    "batch_size = 24\n",
    "num_features =9\n",
    "nb_actions = 3 #[buy, sell, hold]\n",
    "np.random.seed(7)\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(1, num_features), return_sequences=True,stateful=False))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(64, input_shape=(1, num_features), return_sequences=True,stateful=False))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(64,input_shape=(1, num_features), return_sequences=False,stateful=False))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(output_dim=nb_actions))\n",
    "model.add(Activation('linear')) #linear output so we can have range of real-valued outputs\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='Nadam')\n",
    "print(model.summary())\n",
    "\n",
    "import random, timeit\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "indata=X_train\n",
    "episodes = 2\n",
    "gamma = 0.9 #since the reward can be several time steps away, make gamma high\n",
    "epsilon = 0.95\n",
    "batchSize = 100\n",
    "buffer = 100\n",
    "replay = []\n",
    "learning_progress = []\n",
    "#stores tuples of (S, A, R, S')\n",
    "h = 0\n",
    "#signal = pd.Series(index=market_data.index)\n",
    "signal = pd.Series(index=np.arange(len(indata)))\n",
    "\n",
    "for i in range(episodes):\n",
    "    if i == episodes-1: #the last epoch, use test data set\n",
    "        #j=0\n",
    "        state, xdata, price_data = init_state(X_test, test=True)\n",
    "    else:\n",
    "        state, xdata, price_data = init_state(indata)\n",
    "    status = 1\n",
    "    terminal_state = 0\n",
    "    time_step = 14\n",
    "    #while game still in progress\n",
    "    while(status == 1):\n",
    "        #We are in state S\n",
    "        #Let's run our Q function on S to get Q values for all possible actions\n",
    "        qval = model.predict(state, batch_size=1) #Returns a 3 array with value for each action = [sell, buy, Hold]\n",
    "\n",
    "        if (random.random() < epsilon): #choose random action (explore)\n",
    "            action = np.random.randint(1, 4) #assumes 3 different actions\n",
    "        else: #choose best action from Q(s,a) values\n",
    "            \n",
    "            action = (np.argmax(qval))\n",
    "            #if (i == episodes-1) & (signal_SSA['trade'][j]=='no') :\n",
    "            #    action = 3\n",
    "            #    j=j+1\n",
    "        #Take action, observe new state S'\n",
    "        new_state, time_step, signal, terminal_state = take_action(state, xdata, action, signal, time_step)\n",
    "        #Observe reward (it's a value)\n",
    "        reward = get_reward(new_state, time_step, action, price_data, signal, terminal_state)\n",
    "\n",
    "        #Experience replay storage\n",
    "        if (len(replay) < buffer): #if buffer not filled, add to it\n",
    "            replay.append((state, action, reward, new_state)) #store our data\n",
    "            #print(time_step, reward, terminal_state)\n",
    "            \n",
    "        else: #if buffer full, overwrite old values\n",
    "            if (h < (buffer-1)):\n",
    "                h += 1\n",
    "            else:\n",
    "                h = 0\n",
    "            replay[h] = (state, action, reward, new_state)\n",
    "            #randomly sample our experience replay memory\n",
    "            minibatch = random.sample(replay, batchSize)\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            for memory in minibatch:  #So if it was a good choice, the reward will be positive and then the action will be keep for a future similar state.\n",
    "                #Get max_Q(S',a)\n",
    "                old_state, action, reward, new_state = memory\n",
    "                old_qval = model.predict(old_state, batch_size=1) #3 values: [sell, buy, hold]\n",
    "                newQ = model.predict(new_state, batch_size=1)  #Take the set of actions\n",
    "                maxQ = np.max(newQ)\n",
    "                y = np.zeros((1,nb_actions))\n",
    "                y[:] = old_qval[:]\n",
    "                if terminal_state == 0: #non-terminal state\n",
    "                    update = (reward + (gamma * maxQ))\n",
    "                else: #terminal state\n",
    "                    update = reward\n",
    "                y[0][action-1] = update\n",
    "                #print(time_step, reward, terminal_state)\n",
    "                X_train.append(old_state) #The inputs is the 7 features\n",
    "                y_train.append(y.reshape(nb_actions,)) #The output of the neural network is 3\n",
    "                \n",
    "\n",
    "            X_train = np.squeeze(np.array(X_train), axis=(1))\n",
    "            y_train = np.array(y_train)\n",
    "            model.fit(X_train, y_train, batch_size=batchSize, epochs=1, verbose=0)\n",
    "            \n",
    "            state = new_state\n",
    "        if terminal_state == 1: #if reached terminal state, update epoch status\n",
    "            status = 0\n",
    "            \n",
    "        \n",
    "    if epsilon > 0.1: #decrement epsilon over time\n",
    "        epsilon -= (1.0/episodes)\n",
    "    print(i+1)\n",
    "    \n",
    "    ### GIVE INFORMATION ABOUT THE RETURN / PRICE ###\n",
    "    bt = Backtest(pd.Series(data=[x[0,0] for x in xdata]), signal, signalType='shares')\n",
    "    bt.data['delta'] = bt.data['shares'].diff().fillna(0)\n",
    "        \n",
    "        #print(bt.data)\n",
    "    unique, counts = np.unique(filter(lambda v: v==v, signal.values), return_counts=True)\n",
    "#print(np.asarray((unique, counts)).T)\n",
    "    plt.rcParams['figure.figsize']=(20,13)\n",
    "\n",
    "    bt.plotTrades() #Plot the different trades (Hold, Buy or Sold)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"Evolution of the P&L\")\n",
    "    bt.pnl.plot() #Plot the PNL\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSA(object):\n",
    "    \n",
    "    __supported_types = (pd.Series, np.ndarray, list)\n",
    "    \n",
    "    def __init__(self, tseries, L, save_mem=True):\n",
    "        \"\"\"\n",
    "        Decomposes the given time series with a singular-spectrum analysis. Assumes the values of the time series are\n",
    "        recorded at equal intervals.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        tseries : The original time series, in the form of a Pandas Series, NumPy array or list. \n",
    "        L : The window length. Must be an integer 2 <= L <= N/2, where N is the length of the time series.\n",
    "        save_mem : Conserve memory by not retaining the elementary matrices. Recommended for long time series with\n",
    "            thousands of values. Defaults to True.\n",
    "        \n",
    "        Note: Even if an NumPy array or list is used for the initial time series, all time series returned will be\n",
    "        in the form of a Pandas Series or DataFrame object.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Tedious type-checking for the initial time series\n",
    "        if not isinstance(tseries, self.__supported_types):\n",
    "            raise TypeError(\"Unsupported time series object. Try Pandas Series, NumPy array or list.\")\n",
    "        \n",
    "        # Checks to save us from ourselves\n",
    "        self.N = len(tseries)\n",
    "        if not 2 <= L <= self.N/2:\n",
    "            raise ValueError(\"The window length must be in the interval [2, N/2].\")\n",
    "        \n",
    "        self.L = L\n",
    "        self.orig_TS = pd.Series(tseries)\n",
    "        self.K = self.N - self.L + 1\n",
    "        \n",
    "        # Embed the time series in a trajectory matrix\n",
    "        self.X = np.array([self.orig_TS.values[i:L+i] for i in range(0, self.K)]).T\n",
    "        \n",
    "        # Decompose the trajectory matrix\n",
    "        self.U, self.Sigma, VT = np.linalg.svd(self.X)\n",
    "        self.d = np.linalg.matrix_rank(self.X)\n",
    "        \n",
    "        self.TS_comps = np.zeros((self.N, self.d))\n",
    "        \n",
    "        if not save_mem:\n",
    "            # Construct and save all the elementary matrices\n",
    "            self.X_elem = np.array([ self.Sigma[i]*np.outer(self.U[:,i], VT[i,:]) for i in range(self.d) ])\n",
    "\n",
    "            # Diagonally average the elementary matrices, store them as columns in array.           \n",
    "            for i in range(self.d):\n",
    "                X_rev = self.X_elem[i, ::-1]\n",
    "                self.TS_comps[:,i] = [X_rev.diagonal(j).mean() for j in range(-X_rev.shape[0]+1, X_rev.shape[1])]\n",
    "            \n",
    "            self.V = VT.T\n",
    "        else:\n",
    "            # Reconstruct the elementary matrices without storing them\n",
    "            for i in range(self.d):\n",
    "                X_elem = self.Sigma[i]*np.outer(self.U[:,i], VT[i,:])\n",
    "                X_rev = X_elem[::-1]\n",
    "                self.TS_comps[:,i] = [X_rev.diagonal(j).mean() for j in range(-X_rev.shape[0]+1, X_rev.shape[1])]\n",
    "            \n",
    "            self.X_elem = \"Re-run with save_mem=False to retain the elementary matrices.\"\n",
    "            \n",
    "            # The V array may also be very large under these circumstances, so we won't keep it.\n",
    "            self.V = \"Re-run with save_mem=False to retain the V matrix.\"\n",
    "        \n",
    "        # Calculate the w-correlation matrix.\n",
    "        self.calc_wcorr()\n",
    "            \n",
    "    def components_to_df(self, n=0):\n",
    "        \"\"\"\n",
    "        Returns all the time series components in a single Pandas DataFrame object.\n",
    "        \"\"\"\n",
    "        if n > 0:\n",
    "            n = min(n, self.d)\n",
    "        else:\n",
    "            n = self.d\n",
    "        \n",
    "        # Create list of columns - call them F0, F1, F2, ...\n",
    "        cols = [\"F{}\".format(i) for i in range(n)]\n",
    "        return pd.DataFrame(self.TS_comps[:, :n], columns=cols, index=self.orig_TS.index)\n",
    "            \n",
    "    \n",
    "    def reconstruct(self, indices):\n",
    "        \"\"\"\n",
    "        Reconstructs the time series from its elementary components, using the given indices. Returns a Pandas Series\n",
    "        object with the reconstructed time series.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        indices: An integer, list of integers or slice(n,m) object, representing the elementary components to sum.\n",
    "        \"\"\"\n",
    "        if isinstance(indices, int): indices = [indices]\n",
    "        \n",
    "        ts_vals = self.TS_comps[:,indices].sum(axis=1)\n",
    "        return pd.Series(ts_vals, index=self.orig_TS.index)\n",
    "    \n",
    "    def calc_wcorr(self):\n",
    "        \"\"\"\n",
    "        Calculates the w-correlation matrix for the time series.\n",
    "        \"\"\"\n",
    "             \n",
    "        # Calculate the weights\n",
    "        w = np.array(list(np.arange(self.L)+1) + [self.L]*(self.K-self.L-1) + list(np.arange(self.L)+1)[::-1])\n",
    "        \n",
    "        def w_inner(F_i, F_j):\n",
    "            return w.dot(F_i*F_j)\n",
    "        \n",
    "        # Calculated weighted norms, ||F_i||_w, then invert.\n",
    "        F_wnorms = np.array([w_inner(self.TS_comps[:,i], self.TS_comps[:,i]) for i in range(self.d)])\n",
    "        F_wnorms = F_wnorms**-0.5\n",
    "        \n",
    "        # Calculate Wcorr.\n",
    "        self.Wcorr = np.identity(self.d)\n",
    "        for i in range(self.d):\n",
    "            for j in range(i+1,self.d):\n",
    "                self.Wcorr[i,j] = abs(w_inner(self.TS_comps[:,i], self.TS_comps[:,j]) * F_wnorms[i] * F_wnorms[j])\n",
    "                self.Wcorr[j,i] = self.Wcorr[i,j]\n",
    "    \n",
    "    def plot_wcorr(self, min=None, max=None):\n",
    "        \"\"\"\n",
    "        Plots the w-correlation matrix for the decomposed time series.\n",
    "        \"\"\"\n",
    "        if min is None:\n",
    "            min = 0\n",
    "        if max is None:\n",
    "            max = self.d\n",
    "        \n",
    "        if self.Wcorr is None:\n",
    "            self.calc_wcorr()\n",
    "        \n",
    "        ax = plt.imshow(self.Wcorr)\n",
    "        plt.xlabel(r\"$\\tilde{F}_i$\")\n",
    "        plt.ylabel(r\"$\\tilde{F}_j$\")\n",
    "        plt.colorbar(ax.colorbar, fraction=0.045)\n",
    "        ax.colorbar.set_label(\"$W_{i,j}$\")\n",
    "        plt.clim(0,1)\n",
    "        \n",
    "        # For plotting purposes:\n",
    "        if max == self.d:\n",
    "            max_rnge = self.d-1\n",
    "        else:\n",
    "            max_rnge = max\n",
    "        \n",
    "        plt.xlim(min-0.5, max_rnge+0.5)\n",
    "        plt.ylim(max_rnge+0.5, min-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter_pnl=bt.pnl\n",
    "(data_filter_pnl.shape[0]/2)*0.7 #N/2*0.7\n",
    "window = 59 # samples\n",
    "accel_ssa = SSA(data_filter_pnl, window)\n",
    "accel_ssa.plot_wcorr(max=30)\n",
    "plt.title(\"W-Correlation for Walking Time Series (Zoomed)\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_ssa.reconstruct(slice(0,4)).plot()\n",
    "#accel_ssa.reconstruct(slice(12,window)).plot()\n",
    "accel_ssa.orig_TS.plot( alpha=0.5)\n",
    "\n",
    "plt.legend([r\"$\\tilde{F}^{\\mathrm{(signal)}}$\", r\"$\\tilde{F}^{\\mathrm{(noise)}}$\"])\n",
    "plt.title(\"Signal and Noise Components of Toy Time Series, $L = 3726$\")\n",
    "plt.rcParams['figure.figsize']=(20,13)\n",
    "\n",
    "plt.xlabel(r\"$t$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_SSA=pd.DataFrame(accel_ssa.reconstruct(slice(0,4)))\n",
    "signal_SSA['diff']=0\n",
    "signal_SSA['diff'][:(len(signal_SSA)-1)]= np.diff(signal_SSA[0].values)\n",
    "signal_SSA['diff'][(len(signal_SSA))-1]=signal_SSA['diff'][(len(signal_SSA))-2]\n",
    "signal_SSA['trade'] = np.where(signal_SSA['diff']>=0, 'yes', 'no')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
